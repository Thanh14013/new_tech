# Chiáº¿n LÆ°á»£c Dá»± ÄoÃ¡n LTV/ROAS D30-60 theo App+Campaign
## BÃ¡o CÃ¡o PhÃ¢n TÃ­ch & Thiáº¿t Káº¿ Há»‡ Thá»‘ng

**NgÃ y:** 21/01/2026  
**Má»¥c tiÃªu:** Dá»± Ä‘oÃ¡n LTV+ROAS D30-60 tá»« dá»¯ liá»‡u D0-D1 vá»›i sai sá»‘ â‰¤ 5%  
**ÄÆ¡n vá»‹ phÃ¢n tÃ­ch:** App + Campaign (khÃ´ng pháº£i chá»‰ App nhÆ° hiá»‡n táº¡i)

---

## ðŸ“Š 1. Tá»”NG QUAN Dá»® LIá»†U

### 1.1 Quy MÃ´ Dá»¯ Liá»‡u
```
Tá»•ng sá»‘ records:     2,928,239 rows
Khoáº£ng thá»i gian:    01/08/2025 - 31/12/2025 (5 thÃ¡ng)
Unique Apps:         48 apps
Unique Campaigns:    4,766 campaigns
Unique App+Campaign: 4,800 combinations
```

### 1.2 PhÃ¢n Bá»‘ Training vs Test
```
Training Data (T8-T11): 2,356,301 rows (80.5%)
  â””â”€ Thá»i gian: ThÃ¡ng 8-11/2025
  â””â”€ App+Campaign combos: 4,094

Test Data (T12):        571,938 rows (19.5%)
  â””â”€ Thá»i gian: ThÃ¡ng 12/2025
  â””â”€ App+Campaign combos: 2,914
  
Overlap Analysis:
  âœ“ Common combos:     2,160 (cÃ³ trong cáº£ train + test)
  âš  New combos (T12):  754 (chá»‰ xuáº¥t hiá»‡n trong test)
```

**âš ï¸ THÃCH THá»¨C QUAN TRá»ŒNG:**
- **754 combos má»›i** (25.9% test data) chÆ°a tá»«ng xuáº¥t hiá»‡n trong training
- Cáº§n chiáº¿n lÆ°á»£c **fallback** cho cÃ¡c combo nÃ y (dÃ¹ng model app-level hoáº·c campaign-cluster)

### 1.3 Top 10 App+Campaign Combinations

| Rank | App | Campaign | Rows | Installs | LTV D1 | LTV D30 | ROAS D30 | Growth D1â†’D30 |
|------|-----|----------|------|----------|--------|---------|----------|---------------|
| 1 | `com.game.fashion.magic.princess.dressup` | Magic Fashion_ROAS_Tier 3,4 | 24,841 | 4,661,524 | $0.055 | $0.080 | 0.75 | **45%** |
| 2 | `com.game.minicraft.village` | ADROAS_GG_MinicraftVillage_Global | 24,598 | 3,876,480 | $0.019 | $0.030 | 0.69 | **63%** |
| 3 | `com.trending.tik.tap.game.challenge` | ROAS_Tik Tap Challenge_India_IN | 20,278 | 3,659,262 | $0.012 | $0.020 | 0.78 | **66%** |
| 4 | `com.money.run.hypercasual3d` | ADROAS_D0_Uni_Money Run_Global | 19,927 | 3,217,160 | $0.026 | $0.034 | 0.92 | **31%** |
| 5 | `com.scream.imposter.monster.survival` | AdROAS_D0_min_MagicFashion | 19,531 | 3,172,203 | $0.082 | $0.118 | 1.08 | **44%** |

### 1.4 PhÃ¢n TÃ­ch HÃ nh Vi (Behavior Variance)

```
LTV D1 Statistics:
  Mean:  $0.0428
  Std:   $0.0889
  CV:    2.07 (Coefficient of Variation - má»©c Ä‘á»™ biáº¿n Ä‘á»™ng cao)
  Range: $0.00 - $2.21
```

**ðŸ” PHÃT HIá»†N QUAN TRá»ŒNG:**
- **Coefficient of Variation (CV) = 2.07** â†’ Biáº¿n Ä‘á»™ng ráº¥t cao giá»¯a cÃ¡c app+campaign
- Má»™t sá»‘ combo cÃ³ LTV D1 gáº§n $0, sá»‘ khÃ¡c lÃªn tá»›i $2.21
- **Growth D1â†’D30 dao Ä‘á»™ng tá»« 0% Ä‘áº¿n 800%+** â†’ Má»—i combo cÃ³ trajectory hoÃ n toÃ n khÃ¡c biá»‡t
- âž¡ï¸ **Káº¾T LUáº¬N:** KhÃ´ng thá»ƒ dÃ¹ng 1 model chung, Báº®T BUá»˜C pháº£i há»c riÃªng tá»«ng combo

---

## ðŸŽ¯ 2. CHIáº¾N LÆ¯á»¢C MODELING

### 2.1 Hierarchical Modeling Strategy

```
LEVEL 1: App+Campaign Specific Models (Primary)
â”œâ”€ Äiá»u kiá»‡n: Min 300 rows trong training data
â”œâ”€ Models: XGBoost + LightGBM ensemble
â””â”€ Coverage: ~85% test data

LEVEL 2: App-Level Models (Fallback)
â”œâ”€ Äiá»u kiá»‡n: App cÃ³ â‰¥5 campaigns trong training
â”œâ”€ Models: XGBoost + LightGBM vá»›i campaign features
â””â”€ Coverage: ~12% test data (new campaigns trong existing apps)

LEVEL 3: Campaign-Cluster Models (Last Resort)
â”œâ”€ Äiá»u kiá»‡n: Campaign name pattern clustering (ROAS, CPI, etc.)
â”œâ”€ Models: Cluster-based general model
â””â”€ Coverage: ~3% test data (hoÃ n toÃ n má»›i)
```

### 2.2 Feature Engineering Strategy

#### ðŸ“ˆ Core Features (Tá»« D0-D1 Data)
```python
Revenue Metrics (Window: D0-D1):
  - rev_sum         # Tá»•ng revenue D0+D1
  - rev_max         # Max revenue trong D0-D1
  - rev_last        # Revenue D1
  - avg_daily_rev   # Average per day
  - rev_d0_d1_ratio # D1/D0 ratio (momentum)

Velocity Features:
  - velocity_d0_d1  # (D1 - D0) / D0
  - growth_accel    # TÄƒng tá»‘c hay giáº£m tá»‘c
  
User Engagement:
  - retention_d1    # unique_users_day1 / installs
  - engagement_rate # active_days / total_days
  
Cost Efficiency:
  - cpi             # Cost per install
  - roas_d1         # Revenue D1 / Cost
  
Metadata:
  - install_month   # Seasonality
  - geo_tier        # Country tier (T1/T2/T3)
  - campaign_type   # Extracted from name (ROAS, CPI, AdROAS)
```

#### ðŸ§¬ Advanced Features (App+Campaign Specific)
```python
Historical Profile Features (Per Combo):
  - avg_ltv_d30_historical    # Avg LTV D30 cá»§a combo nÃ y trong quÃ¡ khá»©
  - avg_growth_rate           # Avg growth rate D1â†’D30
  - campaign_maturity_days    # Sá»‘ ngÃ y campaign Ä‘Ã£ cháº¡y
  - seasonal_multiplier       # Há»‡ sá»‘ theo thÃ¡ng
  
Comparative Features:
  - ltv_vs_app_avg            # So vá»›i avg cá»§a app
  - ltv_vs_campaign_cluster   # So vá»›i avg cá»§a cluster
  - performance_percentile    # Percentile ranking trong app
```

### 2.3 Model Architecture Per App+Campaign

```
Stage 1: D1 â†’ D14 Prediction
â”œâ”€ Input: D0-D1 features (2 days)
â”œâ”€ Output: LTV D14, ROAS D14
â””â”€ Models: XGBoost + LightGBM (ensemble)

Stage 2: D14 â†’ D30 Prediction
â”œâ”€ Input: D0-D1 features + pred_d14
â”œâ”€ Output: LTV D30, ROAS D30
â””â”€ Models: XGBoost + LightGBM (ensemble)

Stage 3: D30 â†’ D60 Prediction
â”œâ”€ Input: D0-D1 features + pred_d14 + pred_d30
â”œâ”€ Output: LTV D60, ROAS D60
â””â”€ Models: XGBoost + LightGBM (ensemble)
```

**Chained Prediction Strategy:**
- Dá»± Ä‘oÃ¡n D14 trÆ°á»›c
- DÃ¹ng prediction D14 lÃ m feature cho D30
- DÃ¹ng prediction D30 lÃ m feature cho D60
- âž¡ï¸ Giáº£m error propagation báº±ng cÃ¡ch há»c tá»«ng giai Ä‘oáº¡n

---

## ðŸ”¬ 3. PHÃ‚N TÃCH TÃNH KHáº¢ THI

### 3.1 ÄÃ¡nh GiÃ¡ Äá»™ KhÃ³

| Yáº¿u Tá»‘ | ÄÃ¡nh GiÃ¡ | Giáº£i PhÃ¡p |
|--------|----------|-----------|
| **Data Volume** | âœ… Tá»‘t (2.9M rows) | Äá»§ Ä‘á»ƒ train 4,800 models riÃªng |
| **Data Quality** | âš ï¸ Mixed types warning | Clean data preprocessing cáº§n thiáº¿t |
| **Behavior Variance** | ðŸ”´ Cao (CV=2.07) | Hierarchical modeling báº¯t buá»™c |
| **New Combos** | âš ï¸ 25% test data | Fallback strategy LEVEL 2+3 |
| **Target: 5% Error** | ðŸŸ¡ KhÃ³ | Ensemble + chained prediction |

### 3.2 Æ¯á»›c TÃ­nh Sá»‘ LÆ°á»£ng Models

```
Scenario 1: Min 300 rows threshold
  - Eligible combos: ~1,200-1,500
  - Models per combo: 6 (3 stages Ã— 2 models)
  - Total models: ~7,200-9,000

Scenario 2: Min 500 rows threshold (Conservative)
  - Eligible combos: ~800-1,000
  - Models per combo: 6
  - Total models: ~4,800-6,000

Recommendation: Start with Scenario 2 (500 rows threshold)
```

### 3.3 Æ¯á»›c TÃ­nh Thá»i Gian Training

```
Per App+Campaign Combo:
  - Data preprocessing: 5-10s
  - Feature engineering: 10-15s
  - Model training (6 models): 30-60s
  - Total: ~1 minute/combo

Total Training Time:
  - 1,000 combos Ã— 1 min = ~17 hours
  - With parallelization (8 cores): ~2-3 hours
```

---

## ðŸ› ï¸ 4. IMPLEMENTATION PLAN

### Phase 1: Data Preparation (Week 1)
```
âœ“ Clean raw data (handle mixed types)
âœ“ Aggregate by App+Campaign+Install_Date
âœ“ Calculate cumulative revenues (D1, D14, D30, D60)
âœ“ Split train (T8-T11) / test (T12)
âœ“ Identify eligible combos (â‰¥500 rows)
```

### Phase 2: Feature Engineering (Week 1-2)
```
âœ“ Build historical profiles per combo
âœ“ Extract campaign metadata (type, geo, etc.)
âœ“ Calculate velocity & momentum features
âœ“ Create comparative features (vs app avg, vs cluster)
âœ“ Seasonal adjustments
```

### Phase 3: Model Training (Week 2-3)
```
âœ“ Implement hierarchical training pipeline
âœ“ LEVEL 1: Train combo-specific models (500+ rows)
âœ“ LEVEL 2: Train app-level models (fallback)
âœ“ LEVEL 3: Train cluster models (last resort)
âœ“ Hyperparameter tuning per level
âœ“ Save models + metadata
```

### Phase 4: Evaluation & Optimization (Week 3-4)
```
âœ“ Test on T12 data
âœ“ Calculate MAPE (Mean Absolute Percentage Error)
âœ“ Identify combos with >5% error
âœ“ Re-train with adjusted features/hyperparams
âœ“ Ensemble optimization
```

### Phase 5: Production Pipeline (Week 4)
```
âœ“ Build prediction API
âœ“ Model registry & versioning
âœ“ Monitoring dashboard
âœ“ A/B testing framework
```

---

## ðŸ“ˆ 5. EXPECTED PERFORMANCE

### 5.1 Target Metrics

| Metric | Target | Rationale |
|--------|--------|-----------|
| **MAPE D30** | â‰¤ 5% | User requirement |
| **MAPE D60** | â‰¤ 7% | Longer horizon harder |
| **Coverage** | â‰¥ 95% | LEVEL 1+2+3 combined |
| **Inference Time** | < 100ms | Per prediction |

### 5.2 Risk Analysis

| Risk | Probability | Impact | Mitigation |
|------|-------------|--------|------------|
| **New combos (754)** | High | Medium | LEVEL 2+3 fallback |
| **Overfitting** | Medium | High | Cross-validation + regularization |
| **Data drift** | Low | Medium | Monthly retraining |
| **Model complexity** | Medium | Low | Automated pipeline |

---

## ðŸŽ“ 6. ADVANCED TECHNIQUES (Optional Enhancements)

### 6.1 Meta-Learning Approach
```python
# Learn to predict which model architecture works best per combo
MetaFeatures:
  - combo_data_size
  - ltv_variance
  - seasonality_strength
  - campaign_type
  
MetaModel â†’ Recommends: "Use XGBoost with params X" or "Use LSTM"
```

### 6.2 Transfer Learning
```python
# For new combos with <500 rows
1. Start with app-level model weights
2. Fine-tune on combo's limited data
3. Regularization to prevent overfitting
```

### 6.3 Bayesian Hyperparameter Optimization
```python
# Per combo, optimize:
- max_depth, learning_rate, n_estimators
- Using Optuna or HyperOpt
- Budget: 50 trials per combo
```

---

## ðŸ’¡ 7. KEY INSIGHTS & RECOMMENDATIONS

### 7.1 Insights tá»« Data Analysis

1. **Má»—i App+Campaign lÃ  má»™t "doanh nghiá»‡p" riÃªng**
   - Growth rate khÃ¡c biá»‡t: 0% - 800%+
   - LTV range: $0.00 - $2.21
   - âž¡ï¸ One-size-fits-all sáº½ tháº¥t báº¡i

2. **Campaign Type matters**
   - ROAS campaigns: Focus on D7-D14
   - CPI campaigns: Focus on D1-D3
   - AdROAS: Balanced growth
   - âž¡ï¸ Extract campaign type tá»« tÃªn

3. **Seasonality Effect**
   - Install month cÃ³ áº£nh hÆ°á»Ÿng
   - T12 (GiÃ¡ng Sinh) cÃ³ thá»ƒ khÃ¡c biá»‡t
   - âž¡ï¸ Seasonal adjustment cáº§n thiáº¿t

4. **754 New Combos Challenge**
   - 25% test data chÆ°a tháº¥y bao giá»
   - âž¡ï¸ Fallback strategy khÃ´ng thá»ƒ thiáº¿u

### 7.2 Recommendations

#### âœ… DO's:
1. **Start with Top 1,000 combos** (â‰¥500 rows) cho Phase 1
2. **Use chained prediction** (D14 â†’ D30 â†’ D60)
3. **Ensemble XGBoost + LightGBM** cho stability
4. **Monitor per-combo MAPE** vÃ  re-train outliers
5. **Automated retraining pipeline** monthly

#### âŒ DON'Ts:
1. **KhÃ´ng dÃ¹ng 1 model chung** cho táº¥t cáº£
2. **KhÃ´ng ignore new combos** (cáº§n fallback)
3. **KhÃ´ng skip feature engineering** (features quan trá»ng hÆ¡n models)
4. **KhÃ´ng quÃªn validation** (cross-val trong training)
5. **KhÃ´ng hardcode thresholds** (make configurable)

---

## ðŸš€ 8. NEXT STEPS

### Immediate Actions:
```bash
# 1. Clean & prepare data
python scripts/prepare_app_campaign_data.py

# 2. Build hierarchical feature engineering pipeline
python scripts/build_features_per_combo.py

# 3. Train Level 1 models (top 1000 combos)
python scripts/train_combo_models.py --level 1 --min_rows 500

# 4. Train Level 2 fallback models
python scripts/train_combo_models.py --level 2

# 5. Evaluate on T12
python scripts/evaluate_hierarchical.py --test_month T12
```

### Success Criteria:
- [ ] MAPE â‰¤ 5% cho â‰¥80% test data
- [ ] Coverage â‰¥95% (including fallbacks)
- [ ] Inference time <100ms per prediction
- [ ] Model registry vá»›i 4,800+ models

---

## ðŸ“š 9. TECHNICAL SPECIFICATIONS

### 9.1 File Structure (Proposed)
```
models/
â”œâ”€â”€ combo_models/
â”‚   â”œâ”€â”€ {app_id}_{campaign_hash}/
â”‚   â”‚   â”œâ”€â”€ d14_xgb.json
â”‚   â”‚   â”œâ”€â”€ d14_lgb.txt
â”‚   â”‚   â”œâ”€â”€ d30_xgb.json
â”‚   â”‚   â”œâ”€â”€ d30_lgb.txt
â”‚   â”‚   â”œâ”€â”€ d60_xgb.json
â”‚   â”‚   â”œâ”€â”€ d60_lgb.txt
â”‚   â”‚   â”œâ”€â”€ metadata.json
â”‚   â”‚   â””â”€â”€ performance.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ app_models/ (Level 2 fallback)
â”‚   â””â”€â”€ ...
â”œâ”€â”€ cluster_models/ (Level 3 fallback)
â”‚   â””â”€â”€ ...
â””â”€â”€ model_registry.json
```

### 9.2 Metadata Schema
```json
{
  "combo_id": "com.game.minicraft_ADROAS_GG_MinicraftVillage",
  "app_id": "com.game.minicraft.village",
  "campaign": "ADROAS_GG_MinicraftVillage_Global",
  "training_samples": 24598,
  "training_period": "2025-08-01 to 2025-11-30",
  "model_level": 1,
  "performance": {
    "mape_d30": 3.2,
    "mape_d60": 4.8,
    "rmse_d30": 0.012
  },
  "features_used": [...],
  "hyperparameters": {...},
  "created_at": "2026-01-21T10:00:00Z",
  "version": "1.0.0"
}
```

---

## âœ… CONCLUSION

**Feasibility: YES** âœ…  
**Difficulty: HIGH** ðŸ”´  
**Estimated Success Rate: 75-85%** (Ä‘á»ƒ Ä‘áº¡t MAPE â‰¤5% cho â‰¥80% data)

**Key Success Factors:**
1. âœ… Sufficient data volume (2.9M rows)
2. âœ… Clear behavioral differences per combo (justifies separate models)
3. âœ… Hierarchical fallback strategy (handles new combos)
4. âœ… Chained prediction approach (reduces error propagation)
5. âš ï¸ Automated pipeline (critical for 4,800+ models)

**Investment Required:**
- Development Time: 3-4 weeks
- Training Time: 2-3 hours (parallelized)
- Storage: ~5-10GB for models
- Maintenance: Monthly retraining

**Expected ROI:**
- Accuracy improvement: +20-30% vs current app-level approach
- Granular insights per app+campaign
- Scalable to new combos with fallback
- Business impact: Better budget allocation per campaign

---

**Prepared by:** GitHub Copilot  
**Date:** January 21, 2026  
**Version:** 1.0  

*TÃ i liá»‡u nÃ y cung cáº¥p phÃ¢n tÃ­ch toÃ n diá»‡n vÃ  roadmap Ä‘á»ƒ triá»ƒn khai há»‡ thá»‘ng dá»± Ä‘oÃ¡n LTV/ROAS theo App+Campaign. Äá»ƒ báº¯t Ä‘áº§u implement, vui lÃ²ng tham kháº£o Section 8: NEXT STEPS.*
